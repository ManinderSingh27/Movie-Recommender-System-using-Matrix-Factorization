{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix factorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AQVRaxE5qf2",
        "outputId": "e46919b7-8127-48dc-a1ee-ae4764980d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Movie-Recommender-System-using-Matrix-Factorization'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 29 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf Movie Recommender System\n",
        "!git clone https://github.com/ManinderSingh27/Movie-Recommender-System-using-Matrix-Factorization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data vizualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "mKwGX2cx55aU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path += ['Movie-Recommender-System-using-Matrix-Factorization/']"
      ],
      "metadata": {
        "id": "o6nB5-Ye8ju0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utilities as utl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "LuFj-1xY83PP",
        "outputId": "da689a3f-d0a0-4d7b-ec3f-7fa81a35ceec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f74a59d28068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutilities\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilities'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data location\n",
        "ROOT_DIR = 'RecSys-Workshop/'\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'data/ml-100k/')\n",
        "\n",
        "# Read dataset\n",
        "users = pd.read_csv(os.path.join(DATA_DIR, 'u.user'), sep='|', header=None, engine='python', encoding='latin-1')\n",
        "\n",
        "# Columns describing user characteristics\n",
        "users.columns = ['Index', 'Age', 'Gender', 'Occupation', 'Zip code']\n",
        "\n",
        "# Quick overview\n",
        "users.head()"
      ],
      "metadata": {
        "id": "xicoWz94859c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of users x features:', users.shape)"
      ],
      "metadata": {
        "id": "Qugilp0M-UKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of users\n",
        "nb_users = len(users)\n",
        "\n",
        "# Gender: Convert 'M' and 'F' to 0 and 1\n",
        "gender = np.where(np.matrix(users['Gender']) == 'M', 0, 1)[0]\n",
        "\n",
        "print('Shape of gender features:', gender.shape)\n",
        "\n",
        "# Occupation\n",
        "occupation_name = np.array(pd.read_csv(os.path.join(DATA_DIR, 'u.occupation'), \n",
        "                                            sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n",
        "\n",
        "# Boolean transformation of user's occupation\n",
        "occupation_matrix = np.zeros((nb_users, len(occupation_name)))\n",
        "\n",
        "for k in np.arange(nb_users):\n",
        "    occupation_matrix[k, occupation_name.tolist().index(users['Occupation'][k])] = 1\n",
        "\n",
        "print('Shape of user occupation matrix (num of users x num of occupations):', occupation_matrix.shape)\n",
        "\n",
        "# Concatenation of the sociodemographic variables \n",
        "user_attributes = np.concatenate((np.matrix(users['Age']), np.matrix(gender), occupation_matrix.T)).T.tolist()\n",
        "\n",
        "print('Shape of final user attribute matrix: (list of users with 23 features):', len(user_attributes), len(user_attributes[0]))\n"
      ],
      "metadata": {
        "id": "4Ly0epGB-WTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(users['Age'].describe()).T"
      ],
      "metadata": {
        "id": "IpQ_lPHX-YsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utl.barplot(['Women', 'Men'], np.array([np.mean(gender) , 1 - np.mean(gender)]) * 100, \n",
        "            'Sex', 'Percentage (%)', \"User's gender\", 0)"
      ],
      "metadata": {
        "id": "9S33Vs_R-bkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes, scores = utl.rearrange(occupation_name, np.mean(occupation_matrix, axis=0) * 100)\n",
        "utl.barplot(attributes, scores, 'Occupation', 'Percentage (%)', \"Users' occupation\", 90)"
      ],
      "metadata": {
        "id": "9daw7JEv-dh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "movies = pd.read_csv(os.path.join(DATA_DIR, 'u.item'), sep='|', header=None, engine='python', encoding='latin-1')\n",
        "\n",
        "# Number of movies\n",
        "nb_movies = len(movies)\n",
        "print('The number of movies is: ', nb_movies)\n",
        "\n",
        "# Genres\n",
        "movies_genre = np.matrix(movies.loc[:, 5:])\n",
        "movies_genre_name = np.array(pd.read_csv(os.path.join(DATA_DIR, 'u.genre'), sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n",
        "\n",
        "# Quick overview\n",
        "movies.columns = ['Index', 'Title', 'Release', 'The Not a Number column', 'Imdb'] + movies_genre_name.tolist()\n",
        "movies.head()"
      ],
      "metadata": {
        "id": "UibdSHe6-ffq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes, scores = utl.rearrange(movies_genre_name, \n",
        "                                   np.array(np.round(np.mean(movies_genre, axis=0) * 1, 2))[0])\n",
        "utl.barplot(attributes, np.array(scores) * 100, xlabel='Genre', ylabel='Percentage (%)', \n",
        "            title=\" \", rotation = 90)"
      ],
      "metadata": {
        "id": "_6J4-y__-hu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = np.array(pd.read_csv(os.path.join(DATA_DIR, 'u1.base'), delimiter='\\t'), dtype='int')\n",
        "testing_set = np.array(pd.read_csv(os.path.join(DATA_DIR, 'u1.test'), delimiter='\\t'), dtype='int')\n",
        "\n",
        "print('Example sample (user idx, movie idx, rating, timestamp: ', training_set[0])\n",
        "print('Shape of original training and test set with shape:     ', training_set.shape, testing_set.shape)\n"
      ],
      "metadata": {
        "id": "nhjNDdjf-klu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = utl.convert(training_set, nb_users, nb_movies)\n",
        "test_set = utl.convert(testing_set, nb_users, nb_movies)\n",
        "\n",
        "print('Shape of final training set: (list of users x list of all movies):', len(train_set), len(train_set[0]))\n",
        "print('Shape of final test set:     (list of users x list of all movies):', len(test_set), len(test_set[0]))\n"
      ],
      "metadata": {
        "id": "hQR0NZue-mmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_matrix = np.array(train_set)\n",
        "assert train_matrix.shape == (943, 1682)\n",
        "\n",
        "binarized_train_matrix = np.where(train_matrix > 0 , 1, 0)\n",
        "\n",
        "num_movies_watched = np.sum(binarized_train_matrix, axis=1) ## sum across movies for each user\n",
        "pd.DataFrame(num_movies_watched).describe().T"
      ],
      "metadata": {
        "id": "YYfE6duN-osa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns.set(font_scale = 1.5)\n",
        "\n",
        "plt.title('Empirical distribution of \\n the number of movies watched per user')\n",
        "plt.xlabel('Number of movies watched')\n",
        "plt.ylabel('Number of users')\n",
        "plt.hist(num_movies_watched, 100);"
      ],
      "metadata": {
        "id": "SOTLf8R4-sxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_popularity = np.mean(binarized_train_matrix, axis=0)  ## axis 0 refers to averaging across users\n",
        "pd.DataFrame(movie_popularity).describe().T"
      ],
      "metadata": {
        "id": "gDxCuhBJ-vNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Proportion of the population who watched the movie')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.hist(movie_popularity, 100);"
      ],
      "metadata": {
        "id": "QdWpw5Ff-xcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stats_user(data, movies_genre, user_id):\n",
        "    \n",
        "    ratings = data[user_id]\n",
        "    stats = np.zeros(6)\n",
        "    eva = np.zeros((6, movies_genre.shape[1]))\n",
        "\n",
        "    for k in np.arange(len(ratings)):\n",
        "        index = int(ratings[k])\n",
        "        stats[index] += 1\n",
        "        eva[index, :] = eva[index, :] + movies_genre[k]\n",
        "\n",
        "    return stats, eva"
      ],
      "metadata": {
        "id": "lP-uKkKQ-zUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 0\n",
        "num_of_star_ratings, genre_based_ratings = stats_user(train_set, movies_genre, user_id)\n",
        "utl.barplot(np.arange(5) + 1, num_of_star_ratings[1:6] / sum(num_of_star_ratings[1:6]), xlabel='Number of stars', ylabel='Percentage of movies (%)', \n",
        "            title=\" \", rotation = 0)\n"
      ],
      "metadata": {
        "id": "yAxjVknB-1Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, ratio, tensor=False):\n",
        "    train = np.zeros((len(data), len(data[0]))).tolist()\n",
        "    valid = np.zeros((len(data), len(data[0]))).tolist()\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        for j in range(len(data[i])):\n",
        "            if data[i][j] > 0:\n",
        "                if np.random.binomial(1, ratio, 1):\n",
        "                    train[i][j] = data[i][j]\n",
        "                else:\n",
        "                    valid[i][j] = data[i][j]\n",
        "\n",
        "    return [train, valid]\n",
        "\n",
        "train = split(train_set, 0.8)\n",
        "test = test_set"
      ],
      "metadata": {
        "id": "x6Q382_g-27u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learn_to_recommend(data, features=10, lr=0.0002, epochs=101, weigth_decay=0.02, stopping=0.001):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       data: every evaluation\n",
        "       features: number of latent variables\n",
        "       lr: learning rate for gradient descent\n",
        "       epochs: number of iterations or maximum loops to perform\n",
        "       weigth_decay: L2 regularization to predict rattings different of 0\n",
        "       stopping: scalar associated with the stopping criterion\n",
        "      \n",
        "     Returns:\n",
        "       P: latent matrix of users\n",
        "       Q: latent matrix of items\n",
        "       loss_train: vector of the different values of the loss function after each iteration on the train\n",
        "       loss_valid: vector of the different values of the loss function after each iteration not on valid\n",
        "       \"\"\"\n",
        "     \n",
        "    train, valid = data[0], data[1]\n",
        "    nb_users, nb_items = len(train), len(train[0])\n",
        "\n",
        "    # TODO 4.2: Initialization of lists\n",
        "    loss_train, loss_valid= [], []\n",
        "\n",
        "    P = np.random.rand(nb_users, features) * 0.1\n",
        "    Q = np.random.rand(nb_items, features) * 0.1\n",
        "    \n",
        "    for e in range(epochs):        \n",
        "        for u in range(nb_users):\n",
        "            for i in range(nb_items):\n",
        "\n",
        "                # TODO 4.1: Code the condition\n",
        "                if train[u][i]>0:\n",
        "                    error_ui = train[u][i] - prediction(P, Q, u, i)\n",
        "                    P, Q = sgd(error_ui, P, Q, u, i, features, lr, weigth_decay)\n",
        "                               \n",
        "        # TODO 4.2: Code the statistics\n",
        "        loss_train.append(loss(train, P, Q))\n",
        "        loss_valid.append(loss(valid, P, Q))\n",
        "        \n",
        "        if e % 10 == 0:\n",
        "            print('Epoch : ', \"{:3.0f}\".format(e+1), ' | Train :', \"{:3.3f}\".format(loss_train[-1]), \n",
        "                  ' | Valid :', \"{:3.3f}\".format(loss_valid[-1]))\n",
        "\n",
        "        # TODO 4.4: Stopping criterion\n",
        "        #if abs(loss_train[-1]) < stopping:\n",
        "         #   break\n",
        "            \n",
        "        # TODO 4.5 : New stopping criterion\n",
        "        if e>1:\n",
        "          if abs(loss_valid[-1] - loss_valid[-2]) < stopping:\n",
        "            break\n",
        "        \n",
        "    return P, Q, loss_train, loss_valid"
      ],
      "metadata": {
        "id": "OosU-xvk-48Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 5.1:\n",
        "def prediction(P, Q, u, i):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        P: user matrix\n",
        "        Q: matrix of items\n",
        "        u: index associated with user u\n",
        "        i: index associated with item i\n",
        "    Returns:\n",
        "        pred: the predicted evaluation of the user u for the item i\n",
        "    \"\"\"\n",
        "    return np.dot(P[u,:], Q[i,:])\n",
        "\n",
        "def loss(data, P, Q):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       data: ratings\n",
        "       P: matrix of users\n",
        "       Q: matrix of items   \n",
        "    Returns:\n",
        "        MSE: observed mean of squared errors \n",
        "    \"\"\"\n",
        "    errors_sum, nb_evaluations = 0., 0\n",
        "    nb_users, nb_items = len(data), len(data[0])\n",
        "\n",
        "    for u in range(nb_users):\n",
        "        for i in range(nb_items):\n",
        "        \n",
        "            # TODO 5.2:\n",
        "            if data[u][i] > 0:\n",
        "                errors_sum += pow(data[u][i] - prediction(P, Q, u, i), 2)\n",
        "                nb_evaluations += 1\n",
        "                \n",
        "    return errors_sum / nb_evaluations"
      ],
      "metadata": {
        "id": "qZ0WN7rW_Rys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(error, P, Q, id_user, id_item, features, lr, weigth_decay):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        error: difference between observed and predicted evaluation (in that order)\n",
        "        P: matrix of users\n",
        "        Q: matrix of items\n",
        "        id_user: id_user\n",
        "        id_item: id_item\n",
        "        features: number of latent variables\n",
        "        lr: learning for the descent of the gradient\n",
        "        weigth_decay: scalar multiplier controlling the influence of the regularization term\n",
        "       \n",
        "     Returns:\n",
        "        P: the new estimate for P\n",
        "        Q: the new estimate for Q\n",
        "     \"\"\"    \n",
        "    \n",
        "    # TODO 6.1 :\n",
        "    for f in range(features):\n",
        "        P[id_user, f] = P[id_user, f] + lr * (2 * Q[id_item, f] * error - 2 * weigth_decay * P[id_user, f])\n",
        "        Q[id_item, f] = Q[id_item, f] + lr * (2 * P[id_user, f] * error - 2 * weigth_decay * Q[id_item, f])\n",
        "    return P, Q"
      ],
      "metadata": {
        "id": "n-64tRbC_UB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = 5\n",
        "lr = 0.01\n",
        "epochs = 101\n",
        "weigth_decay = 0.02\n",
        "stopping = 0.01\n",
        "\n",
        "P, Q, loss_train, loss_valid = learn_to_recommend(train, features, lr, epochs, weigth_decay, stopping)"
      ],
      "metadata": {
        "id": "rQ1WUo2L_feg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(len(loss_train)))\n",
        "k=0\n",
        "\n",
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns.set(font_scale = 1.5)\n",
        "\n",
        "plt.plot(x[-k:], loss_train[-k:], 'r', label=\"Train\")\n",
        "plt.plot(x[-k:], loss_valid[-k:], 'g', label=\"Validation\")\n",
        "plt.title('Learning curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "leg = plt.legend(loc='best', shadow=True, fancybox=True)"
      ],
      "metadata": {
        "id": "m-zfNue3_hdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss(test, P, Q)"
      ],
      "metadata": {
        "id": "heZ051Bg_jN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explore(movie_titles, latent_matrix, frequency_mask, factor_idx, k):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       movie_titles: Pandas Series containing movie titles\n",
        "        latent_matrix: matrix containing the model parameters for movies\n",
        "        frequency_mask: boolean array masking non-frequent movies\n",
        "        factor_idx: index of the latent variable\n",
        "        k: number of movies to show\n",
        "\n",
        "    Returns:\n",
        "        names: movie titles\n",
        "        scores: associated predicted ratings of movies\n",
        "    \"\"\"\n",
        "\n",
        "    # slice the column to obtain latent variable, then apply mask\n",
        "    latent_variable = latent_matrix[:, factor] * frequency_mask\n",
        "\n",
        "    # filter out infrequent movies\n",
        "    nonzero_indices = np.nonzero(latent_variable)\n",
        "    movies = np.array(movie_titles)[nonzero_indices][:k]\n",
        "    latent_variable = latent_variable[nonzero_indices][:k]\n",
        "\n",
        "    return movies, latent_variable\n"
      ],
      "metadata": {
        "id": "28-inilIAoEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_popularity)\n",
        "print(movie_popularity.shape)"
      ],
      "metadata": {
        "id": "GTr52fwGA4rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "factor = 0\n",
        "threshold = 0.1\n",
        "names, scores = explore(movies['Title'], Q, np.where(movie_popularity > threshold, 1, 0), factor, k)\n",
        "\n",
        "df = pd.DataFrame(np.matrix((names, scores)).T, (np.arange(len(scores)) + 1).tolist())\n",
        "df.columns = ['Title', 'Latent factor']\n",
        "df"
      ],
      "metadata": {
        "id": "_t7eYetiA647"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_top_k(names, ratings, k=10):\n",
        "   \"\"\"\n",
        "   Example:\n",
        "   a, b = np.array(['a', 'b', 'c']), np.array([6, 1, 3])\n",
        "   a, b = rank_top_k(a, b, k=2)\n",
        "   >>> a\n",
        "   np.array('a', 'c')\n",
        "   >>> b\n",
        "   np.array([6, 3])\n",
        "   \"\"\"\n",
        " \n",
        "   # rank indices in descending order\n",
        "   ranked_ids = np.argsort(ratings)[::-1]\n",
        " \n",
        "   return names[ranked_ids][:k], ratings[ranked_ids][:k]"
      ],
      "metadata": {
        "id": "iCuzNwjPA8MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 0\n",
        "top_k = 10\n",
        "\n",
        "# TODO: 10.1\n",
        "# Step 1: Define the user's preferences using the training set.\n",
        "user_train = np.array(train[0][user_id])\n",
        "\n",
        "\n",
        "# Step 2: Define what movies the user has not seen yet.\n",
        "# We will only generate recommendations for these movies, so make sure we store this in an awway equal to the number of all movies.\n",
        "movies_not_seen = np.where(user_train == 0, 1, 0)\n",
        "\n",
        "\n",
        "# Step 3: Predict the user's ratings across all movies.\n",
        "estimates = np.dot(P[user_id, :], Q.T)\n",
        "\n",
        "\n",
        "# Step 4: Consider the estimated ratings for movies that were not seen by the user.\n",
        "unseen_movie_estimates = estimates * movies_not_seen\n",
        "\n",
        "\n",
        "# Step 5: Retrieve the top k recommendations for that user.\n",
        "recommendations, scores = rank_top_k(np.array(movies['Title']), unseen_movie_estimates, k=top_k)\n",
        "\n",
        "\n",
        "# Step 6: Show the title and associated latent feature of the recommendations\n",
        "df = pd.DataFrame(np.matrix((recommendations, scores)).T, (np.arange(10) + 1).tolist(), \n",
        "                  columns=['Title', 'Predicted rating'])\n",
        "df\n"
      ],
      "metadata": {
        "id": "GJdClRXZA-k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(user_id, data, P, Q, list_of_genre_names, movies_genre, genre):\n",
        "    \"\"\"\n",
        "    args:\n",
        "       user_id: user_id\n",
        "        data: user-item ratings\n",
        "        P: user matrix\n",
        "        Q: item matrix\n",
        "        list_of_genre_names: list of genre names\n",
        "        movies_genre: user's preference for genres\n",
        "        new: Boolean, do we want to make new recommendations or not?\n",
        "\n",
        "    Returns:\n",
        "        the best suggestions based on the genre of movie selected\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO 11.1\n",
        "    place = movies_genre_name.tolist().index(genre)   \n",
        "    genre = np.array(movies_genre[:, place])\n",
        "    predictions = np.array(np.dot(P[user_id, :], Q.T))\n",
        "    \n",
        "    return np.array(predictions) * np.array(genre.T)[0]"
      ],
      "metadata": {
        "id": "WZnzdePCBBTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movies_genre_name)\n",
        "print(movies_genre.shape)"
      ],
      "metadata": {
        "id": "vm__W_xqBDl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre = \"Animation\"\n",
        "user_id = 1\n",
        "top_k = 5\n",
        " \n",
        "# Estimate recommendations\n",
        "estimates = recommend(user_id, train, P, Q, list_of_genre_names=movies_genre_name, movies_genre=movies_genre, genre=genre)\n",
        " \n",
        "recommendations, scores = rank_top_k(np.array(movies['Title']), estimates, k=top_k)\n",
        " \n",
        "# Presentation\n",
        "df = pd.DataFrame(np.matrix((recommendations, scores)).T, (np.arange(top_k) + 1).tolist(), columns = ['Title', 'Predicted rating'])\n",
        "df"
      ],
      "metadata": {
        "id": "HinMogmpBHrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CLOaIs_SBZj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}